{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0baae95d",
   "metadata": {},
   "source": [
    "# Lab Exercise 05\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16353a40",
   "metadata": {},
   "source": [
    "## More Pandas Functions!\n",
    "\n",
    "We have been given a dataset split into two csv files: stroke_data_01.csv and stroke_data_02.csv. Both files have unique variables pertaining to a cohort of patients. *Source: [Stroke prediction dataset](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset?resource=download)*\n",
    "\n",
    "stroke_data_01.csv:\n",
    "- `id`: unique identifier\n",
    "- `hypertension`: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension\n",
    "- `heart_disease`: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease\n",
    "- `avg_glucose_level`: average glucose level in blood\n",
    "- `bmi`: body mass index\n",
    "- `smoking_status`: \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"*\n",
    "- `stroke`: 1 if the patient had a stroke or 0 if not\n",
    "\n",
    "stroke_data_02.csv:\n",
    "- `id`: unique identifier\n",
    "- `gender`: \"Male\", \"Female\" or \"Other\"\n",
    "- `age`: age of the patient\n",
    "- `ever_married`: \"No\" or \"Yes\"\n",
    "- `work_type`: \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"\n",
    "- `Residence_type`: \"Rural\" or \"Urban\"\n",
    "\n",
    "Our first step is load these datasets into two pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916f2fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas module with alias pd\n",
    "import pandas as pd\n",
    "\n",
    "# Load our data\n",
    "df1 = pd.read_csv(\"stroke_data_01.csv\")\n",
    "df2 = pd.read_csv(\"stroke_data_02.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398c9bac",
   "metadata": {},
   "source": [
    "Let's take a quick look at our first dataframe, `df1`, using the `head()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54fa859",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c15d1e",
   "metadata": {},
   "source": [
    "It looks like all of the variables are there and match the information we were given.\n",
    "\n",
    "Now let's check out `df2` using `head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dc0cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ec1209",
   "metadata": {},
   "source": [
    "We can get some descriptive statistics quickly by using the `describe()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35deeff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbeb13a",
   "metadata": {},
   "source": [
    "This function provides total number of non NaN values, mean, standard deviation, min, max, and 25th, 50th (median), and 75th percentiles. This is a very helpful function, especially for continuous data types.\n",
    "\n",
    "What happens when we run `describe()` on `df2`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474bf5fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511d94f6",
   "metadata": {},
   "source": [
    "For `df2` you see that only age shows up. This is because age is the only variable (column) that has an int or float data type. `describe()` is not as useful for this dataframe because most of the columns are categorial variable (str).\n",
    "\n",
    "Later we will discuss a method that can be very helpful for quickly viewing and understanding categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0b075b",
   "metadata": {},
   "source": [
    "As mentioned previously, these two dataframes are actually part of the same dataset, meaning all of the patients are the same across both dataframes. It would be much easier to work with all of the data in a single dataframe.\n",
    "\n",
    "We can do this by joining the two dataframes. We will use the `merge()` method to match the patients based on a specific variable (`id`). We will merge `df2` to `df1` using left join (`how='left'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b8b70f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df1.merge(df2, on='id', how='left')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9f3daf",
   "metadata": {},
   "source": [
    "Left join allows us to use the dataframe to which the method was applied, `df1`, and return all rows from that dataframe, while also returning columns from the \"right\" dataframe, `df2`, if the row matches specific data from the \"left\" dataframe (`id`).\n",
    "\n",
    "You can modify how this is done by changing the `how` argument to \"right\", \"inner\", etc. Here are the definitions for each option (from the Pandas Documentation):\n",
    "- left: use only keys from left frame, similar to a SQL left outer join; preserve key order.\n",
    "- right: use only keys from right frame, similar to a SQL right outer join; preserve key order.\n",
    "- outer: use union of keys from both frames, similar to a SQL full outer join; sort keys lexicographically.\n",
    "- inner: use intersection of keys from both frames, similar to a SQL inner join; preserve the order of the left keys.\n",
    "\n",
    "The below figure can help visualize the difference among these options.\n",
    "![join](img/pandas_merge.png)\n",
    "*Source: https://www.datasciencemadesimple.com/join-merge-data-frames-pandas-python/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c06f04",
   "metadata": {},
   "source": [
    "Now that we have a single dataframe, we can start cleaning it up. First, let's look at the all of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf19727",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f3ba8f",
   "metadata": {},
   "source": [
    "For consistency, let's change the name of `Residence_type` to all lower case. We can do this using the `rename()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f292683c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'Residence_type':'residence_type'},inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fec7b7",
   "metadata": {},
   "source": [
    "Next, we will make the `id` column the index column for the dataframe. We will use the `set_index()` method to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d7a0de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.set_index('id',inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5f5e6c",
   "metadata": {},
   "source": [
    "Next, we will look at the frequencies for different values for each column. We will do this using the `value_counts()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e94db2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba5a925",
   "metadata": {},
   "source": [
    "Using the method on the full dataframe is not very helpful as it shows the frequency for each unique combination of values acorss all columns. Let's clean this up by selecting individual columns.\n",
    "\n",
    "Let's see the frequency of patients based on presence/absence of hyptertension, then we will look at frequnecy based on hypertension and heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccd0086",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.value_counts(subset=['hypertension'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7cf497",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.value_counts(subset=['hypertension','heart_disease'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259d6db7",
   "metadata": {},
   "source": [
    "This easily allowed us view how many patients fall within these 4 different groups. We can further this analysis and use `groupby()` to get the patients in the same groups that we defined with `value_counts()`, but we will calculate the median for all of the other float variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332fc6ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby(['hypertension','heart_disease']).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3382e9",
   "metadata": {},
   "source": [
    "Let us bring our attention to the categorical (str) variables. We can quickly assess what values exist for these columns using `unique()`. This will return an array of the unique values for a given column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cb1e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.residence_type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a60888",
   "metadata": {},
   "source": [
    "So `residence_type` has two possible values: \"Rural\" or \"Urban\".\n",
    "\n",
    "We can use the `nunique()` method to output how many unique values exist for a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719fc2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.residence_type.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d31498",
   "metadata": {},
   "source": [
    "For some columns, we may want to change a continuous variable to a discretized value. We can accomplish this by binning the values for a column using the `cut()` or `qcut()` functions.\n",
    "\n",
    "`cut()` allows the user to bin data for a selected column using user defined cutoffs and labels for the bins. We will apply this function to the `age` column and create a `age_bin` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf6abc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age_bin'] = pd.cut(df['age'], bins=[0,20,40,60,80], labels=['<20','21-40','41-60','>61'])\n",
    "df.value_counts(subset='age_bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfc8eae",
   "metadata": {},
   "source": [
    "`qcut()` is very similar, but it automatically defines the bins by calculating the `q` quantiles. The labels will be named based on the calculated bin range. We will choose 4 quantiles to mimic what we did with the previous binning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9bdba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age_bin'] = pd.qcut(df['age'], q=4)\n",
    "df.value_counts(subset='age_bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db49cad",
   "metadata": {},
   "source": [
    "# Graded Portion\n",
    "\n",
    "---\n",
    "\n",
    "For all three problems, you must first load the dataset \"stroke_data.csv\" as `df`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae08c6f2",
   "metadata": {},
   "source": [
    "## Problem 01 (5 points)\n",
    "\n",
    "Change the values of column `Residence_type` from 'Urban' and 'Rural' to 0 and 1, respectively. Also change the values for `smoking_status` from 'formerly smoked', 'never smoked', 'smokes', and 'Unknown' to 0, 1, 2, and 3, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f1a1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here to answer the question\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6a6e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "print(df['Residence_type'].unique().tolist()==[0,1])\n",
    "print(df['smoking_status'].unique().tolist()==[0,1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dc7aec",
   "metadata": {},
   "source": [
    "## Problem 02 (5 points)\n",
    "\n",
    "Bin `avg_glucose_level` into 4 quantiles, label the bins as `[0,1,2,3]`, and calculate the frequency of patients for each of the 4 groups. Assign the frequency Series as a variable named `glucose_freq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523b20dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here to answer the question\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f1daf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "print(glucose_freq[0]==1278)\n",
    "print(glucose_freq[1]==1278)\n",
    "print(glucose_freq[2]==1277)\n",
    "print(glucose_freq[3]==1277)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daaf3cd",
   "metadata": {},
   "source": [
    "## Problem 03 (10 points)\n",
    "\n",
    "Calculate the mean `bmi` based on `gender`, round the mean values to 2 decimals places, then replace any `bmi` NaN values with the calculated median `bmi` corresponding to each patient's `gender`. Modify the exisiting dataframe (`df`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2c66a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here to answer the question\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55a93dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "print(df.loc[1,'bmi']==29.07)\n",
    "print(df.loc[13,'bmi']==28.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2610b71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
